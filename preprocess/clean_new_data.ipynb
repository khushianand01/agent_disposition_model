{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "1",
            "metadata": {},
            "source": [
                "# Data Cleaning and Conversion for Call Disposition Model\n",
                "\n",
                "This notebook cleans the raw Excel data from `data/raw/missing_data.xlsx` and converts it into the structured JSON format required for training.\n",
                "\n",
                "**Note:** For bulk processing of 100k+ rows, the Python script `preprocess/run_cleaning.py` is faster and recommended."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import json\n",
                "import numpy as np\n",
                "from tqdm import tqdm\n",
                "import re\n",
                "import os\n",
                "\n",
                "# File paths (relative to notebook location)\n",
                "INPUT_FILE = '../data/raw/missing_data.xlsx'\n",
                "OUTPUT_FILE = '../data/calls_data.json'\n",
                "\n",
                "print(f\"Loading data from {INPUT_FILE}...\")\n",
                "df = pd.read_excel(INPUT_FILE)\n",
                "print(f\"Total rows loaded: {len(df)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3",
            "metadata": {},
            "source": [
                "## 1. Cleaning Utilities"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4",
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_val(val):\n",
                "    \"\"\"Deep cleaning of a single value for JSON serializability.\"\"\"\n",
                "    if pd.isna(val) or str(val).strip().lower() in ['nat', 'nan', 'null', 'none', '']:\n",
                "        return None\n",
                "    if isinstance(val, (pd.Timestamp, np.datetime64)) or 'datetime' in str(type(val)).lower():\n",
                "        try:\n",
                "            return str(val).split(' ')[0]\n",
                "        except:\n",
                "            return None\n",
                "    if isinstance(val, (np.integer, int)):\n",
                "        return int(val)\n",
                "    if isinstance(val, (np.floating, float)):\n",
                "        return float(val)\n",
                "    return val\n",
                "\n",
                "def format_transcript(text):\n",
                "    if not isinstance(text, str):\n",
                "        return \"\"\n",
                "    # Standardize Speaker labels\n",
                "    text = text.replace(\"Speaker 0:\", \"Agent:\")\n",
                "    text = text.replace(\"Speaker 1:\", \"Borrower:\")\n",
                "    # Remove any other Speaker labels (Speaker 2, Speaker 3, etc.)\n",
                "    text = re.sub(r\"Speaker \\d+:\", \"\", text)\n",
                "    # Clean redundant spaces\n",
                "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
                "    return text\n",
                "\n",
                "def map_payment_disposition(val):\n",
                "    if pd.isna(val): return None\n",
                "    v = str(val).upper().strip()\n",
                "    if v in ['PTP', 'WILLING_TO_PAY', 'PROMISE_TO_PAY']: return 'PTP'\n",
                "    if v in ['PAID', 'ALREADY_PAID_BEFORE_CALL', 'FULL_PAID_ON_CALL', 'PAYMENT_COMPLETED']: return 'PAID'\n",
                "    if v in ['SETTLEMENT', 'WANT_TO_SETTLE', 'SETTLED_AFTER_CALL', 'ALREADY_SETTLED_BEFORE_CALL', 'SETTLEMENT_NEGOTIATION']: return 'SETTLEMENT'\n",
                "    if v in ['PARTIAL_PAYMENT', 'PARTIALLY_PAID_AFTER_CALL']: return 'PARTIAL_PAYMENT'\n",
                "    return val\n",
                "\n",
                "def clean_remarks(remarks):\n",
                "    if not remarks or not isinstance(remarks, str) or \"Synthetic\" in remarks:\n",
                "        return None\n",
                "    return remarks"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5",
            "metadata": {},
            "source": [
                "## 2. Process and Filter Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6",
            "metadata": {},
            "outputs": [],
            "source": [
                "INSTRUCTION = \"\"\"You are an AI assistant that extracts structured call disposition data.\n",
                "Given a call transcript between an agent and a borrower, extract the following fields. Return ONLY valid JSON. Do not explain.:\n",
                "disposition, payment_disposition, reason_for_not_paying, ptp_amount, ptp_date, followup_date, remarks.\n",
                "Current Date: 2026-01-27\n",
                "If a field is not present, return null.\"\"\"\n",
                "\n",
                "json_data = []\n",
                "dropped_count = 0\n",
                "\n",
                "print(\"Processing, cleaning, and filtering rows...\")\n",
                "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
                "    disposition = clean_val(row['disposition'])\n",
                "    transcription = format_transcript(row['transcription'])\n",
                "    \n",
                "    # Filter: Remove if disposition or transcription is null/empty\n",
                "    if not disposition or not transcription or transcription.strip() == \"\":\n",
                "        dropped_count += 1\n",
                "        continue\n",
                "\n",
                "    output_obj = {\n",
                "        \"disposition\": disposition,\n",
                "        \"payment_disposition\": map_payment_disposition(row['payment_disposition']),\n",
                "        \"reason_for_not_paying\": clean_val(row['reason_for_not_paying']),\n",
                "        \"ptp_amount\": clean_val(row['ptp_amount']),\n",
                "        \"ptp_date\": clean_val(row['ptp_date']),\n",
                "        \"followup_date\": clean_val(row['followup_date']),\n",
                "        \"remarks\": clean_remarks(str(row['remarks'])) if pd.notna(row['remarks']) else None\n",
                "    }\n",
                "    \n",
                "    entry = {\n",
                "        \"instruction\": INSTRUCTION,\n",
                "        \"input\": transcription,\n",
                "        \"output\": output_obj\n",
                "    }\n",
                "    json_data.append(entry)\n",
                "\n",
                "print(f\"Dropped {dropped_count} rows due to null transcripts or dispositions.\")\n",
                "print(f\"Total entries preserved: {len(json_data)}\")\n",
                "\n",
                "print(f\"Saving to {OUTPUT_FILE}...\")\n",
                "with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
                "    json.dump(json_data, f, indent=2, ensure_ascii=False, default=lambda x: None if pd.isna(x) else str(x))\n",
                "\n",
                "print(\"Done!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}